{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094f617d-4899-4428-a6cc-c6b9b027c255",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdac296-1121-4528-a6fb-b10597f1b386",
   "metadata": {},
   "source": [
    "- We use `torch`package.\n",
    "- We use `pytorch_lightning` packages to simplify fitting and evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bd6b71",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import \\\n",
    "     (LinearRegression,\n",
    "      LogisticRegression,\n",
    "      Lasso)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b799d88",
   "metadata": {},
   "source": [
    "### Torch-Specific Imports\n",
    "There are a number of imports for `torch`. (These are not\n",
    "included with `ISLP`, so must be installed separately.)\n",
    "First we import the main library\n",
    "and essential tools used to specify sequentially-structured networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d64db-af55-48a3-bb2f-acddf81c9ad6",
   "metadata": {},
   "source": [
    "- Main library and essential tools to specify sequentially-structured networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3298bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cce9d-038e-4154-829a-f145909e6eda",
   "metadata": {},
   "source": [
    "- Tools from `torchmetrics` to compute metrics to evaluate performance.\n",
    "- Tools from `torchinfo` to summarize info of the layers of a model.\n",
    "    - `read_image()` load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aeae9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import (MeanAbsoluteError, R2Score)\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3e7e5-013f-460b-8cd6-0c4ef6792d8e",
   "metadata": {},
   "source": [
    "- `pytorch_lightning` package simplifies the specification and fitting and evaluate models by reducing amount of boilerplate code needed.\n",
    "- `pytorch_lightning` is higher-level interface than `torch`.\n",
    "- `pytorch_lightning` is a high-level module for fitting `torch` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a39702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b27f4d",
   "metadata": {},
   "source": [
    "- `seed_everything()` set seed.\n",
    "- `use_deterministic_algorithms` fix algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bf06a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(0, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd719f8",
   "metadata": {},
   "source": [
    "- We use datasets from `torchvision`.\n",
    "- We use transforms from `torchvision` for preprocessing.\n",
    "- We use a pretrained network for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062cd869",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.datasets import MNIST, CIFAR100\n",
    "from torchvision.models import (resnet50, ResNet50_Weights)\n",
    "from torchvision.transforms import (Resize, Normalize,\n",
    "                                    CenterCrop, ToTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a507a",
   "metadata": {},
   "source": [
    "- `SimpleDataModule` and `SimpleModule` from `ISLP.torch` are simple versions of objects used in `pytorch_lightning`.\n",
    "- `ErrorTracker` collects targets and predictions over each mini-batch during validation or testing, enabling metric computation over the entire validation or test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a05884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.torch import (SimpleDataModule, SimpleModule,\n",
    "                        ErrorTracker, rec_num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b882b7-e23d-4ff0-821d-c859fc88c60a",
   "metadata": {},
   "source": [
    "- We use helper functions from `ISLP.torch.imdb` to load data, lookup that maps integers to keys in data.\n",
    "- We use a modified copy of the preprocessed `imdb` data from `keras`. It saves time for preprocessing.\n",
    "    - `keras` is a separate package for fitting deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1474e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP.torch.imdb import (load_lookup, load_tensor,\n",
    "                             load_sparse, load_sequential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a9d9b2-b2f7-44e4-971f-1d6ef923e63d",
   "metadata": {},
   "source": [
    "- We use `glob()` from `glob` package to find all files matching wildcard characters.\n",
    "- We use `json` module to load JSON file for looking up classes to identify labels of the pictures in `ResNet50`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100ff28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from glob import glob; import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe853eb1-e782-4f8c-b1cc-fb20a3a5aec2",
   "metadata": {},
   "source": [
    "# New York Stock Exchange Data\n",
    "- Data consisting of the Dow Jones returns, log trading volume, and log volatility for the New York Stock Exchange over a 20 year period\n",
    "- There are 6051 rows. Row index is the date which has format YYYY-MM-DD.\n",
    "- There are 5 variables:\n",
    "    - day_of_week: Day of the week (mon, tues, wed, thur, fri)\n",
    "    - DJ_return: Return for Dow Jones Industrial Average\n",
    "    - log_volume: Log of trading volume\n",
    "    - log_volatility: Log of volatility\n",
    "    - train: For the first 4,281 observations, this is set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed823e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>DJ_return</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>log_volatility</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-12-03</th>\n",
       "      <td>mon</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>-13.127403</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-04</th>\n",
       "      <td>tues</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.346202</td>\n",
       "      <td>-11.749305</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-05</th>\n",
       "      <td>wed</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.525306</td>\n",
       "      <td>-11.665609</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-06</th>\n",
       "      <td>thur</td>\n",
       "      <td>-0.003462</td>\n",
       "      <td>0.210182</td>\n",
       "      <td>-11.626772</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-07</th>\n",
       "      <td>fri</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.044187</td>\n",
       "      <td>-11.728130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_of_week  DJ_return  log_volume  log_volatility  train\n",
       "date                                                                \n",
       "1962-12-03         mon  -0.004461    0.032573      -13.127403   True\n",
       "1962-12-04        tues   0.007813    0.346202      -11.749305   True\n",
       "1962-12-05         wed   0.003845    0.525306      -11.665609   True\n",
       "1962-12-06        thur  -0.003462    0.210182      -11.626772   True\n",
       "1962-12-07         fri   0.000568    0.044187      -11.728130   True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYSE = load_data('NYSE')\n",
    "NYSE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "326fdcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DJ_return</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>log_volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6051.000000</td>\n",
       "      <td>6051.000000</td>\n",
       "      <td>6051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000177</td>\n",
       "      <td>-0.008336</td>\n",
       "      <td>-9.842713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.233684</td>\n",
       "      <td>0.753937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.047177</td>\n",
       "      <td>-1.322425</td>\n",
       "      <td>-13.127403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.004640</td>\n",
       "      <td>-0.159956</td>\n",
       "      <td>-10.334196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>-0.013249</td>\n",
       "      <td>-9.843592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.131632</td>\n",
       "      <td>-9.379632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.049517</td>\n",
       "      <td>1.039370</td>\n",
       "      <td>-7.477833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DJ_return   log_volume  log_volatility\n",
       "count  6051.000000  6051.000000     6051.000000\n",
       "mean      0.000177    -0.008336       -9.842713\n",
       "std       0.008436     0.233684        0.753937\n",
       "min      -0.047177    -1.322425      -13.127403\n",
       "25%      -0.004640    -0.159956      -10.334196\n",
       "50%       0.000125    -0.013249       -9.843592\n",
       "75%       0.004792     0.131632       -9.379632\n",
       "max       0.049517     1.039370       -7.477833"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYSE.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7df978",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "353e06fd-5ed5-4325-819e-88e3cba575ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "cols = ['DJ_return', 'log_volume', 'log_volatility']\n",
    "X = pd.DataFrame(StandardScaler(\n",
    "                     with_mean=True,\n",
    "                     with_std=True).fit_transform(NYSE[cols]),\n",
    "                 columns=NYSE[cols].columns,\n",
    "                 index=NYSE.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8229ac-2a27-4dfe-8f52-db0a5d9e272b",
   "metadata": {},
   "source": [
    "- We set up the lagged versions of the data, dropping any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d562e0-4b05-4884-9788-5cf1b526eaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DJ_return</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>log_volatility</th>\n",
       "      <th>DJ_return_1</th>\n",
       "      <th>log_volume_1</th>\n",
       "      <th>log_volatility_1</th>\n",
       "      <th>DJ_return_2</th>\n",
       "      <th>log_volume_2</th>\n",
       "      <th>log_volatility_2</th>\n",
       "      <th>DJ_return_3</th>\n",
       "      <th>log_volume_3</th>\n",
       "      <th>log_volatility_3</th>\n",
       "      <th>DJ_return_4</th>\n",
       "      <th>log_volume_4</th>\n",
       "      <th>log_volatility_4</th>\n",
       "      <th>DJ_return_5</th>\n",
       "      <th>log_volume_5</th>\n",
       "      <th>log_volatility_5</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-12-10</th>\n",
       "      <td>-1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-4.36</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-11</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-12</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DJ_return  log_volume  log_volatility  DJ_return_1  log_volume_1  \\\n",
       "date                                                                           \n",
       "1962-12-10      -1.30        0.61           -1.37         0.05          0.22   \n",
       "1962-12-11      -0.01       -0.01           -1.51        -1.30          0.61   \n",
       "1962-12-12       0.38        0.04           -1.55        -0.01         -0.01   \n",
       "\n",
       "            log_volatility_1  DJ_return_2  log_volume_2  log_volatility_2  \\\n",
       "date                                                                        \n",
       "1962-12-10             -2.50        -0.43          0.94             -2.37   \n",
       "1962-12-11             -1.37         0.05          0.22             -2.50   \n",
       "1962-12-12             -1.51        -1.30          0.61             -1.37   \n",
       "\n",
       "            DJ_return_3  log_volume_3  log_volatility_3  DJ_return_4  \\\n",
       "date                                                                   \n",
       "1962-12-10         0.43          2.28             -2.42         0.91   \n",
       "1962-12-11        -0.43          0.94             -2.37         0.43   \n",
       "1962-12-12         0.05          0.22             -2.50        -0.43   \n",
       "\n",
       "            log_volume_4  log_volatility_4  DJ_return_5  log_volume_5  \\\n",
       "date                                                                    \n",
       "1962-12-10          1.52             -2.53        -0.55          0.18   \n",
       "1962-12-11          2.28             -2.42         0.91          1.52   \n",
       "1962-12-12          0.94             -2.37         0.43          2.28   \n",
       "\n",
       "            log_volatility_5  train  \n",
       "date                                 \n",
       "1962-12-10             -4.36   True  \n",
       "1962-12-11             -2.53   True  \n",
       "1962-12-12             -2.42   True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for lag in range(1, 6): # Create lags from 1 to 5\n",
    "    for col in cols:\n",
    "        newcol = np.zeros(X.shape[0]) * np.nan\n",
    "        newcol[lag:] = X[col].values[:-lag]\n",
    "        # Create a new col with name col_lag and add to X\n",
    "        X.insert(len(X.columns), \"{0}_{1}\".format(col, lag), newcol)\n",
    "# Add the original column 'train' to X\n",
    "X.insert(len(X.columns), 'train', NYSE['train'])\n",
    "X = X.dropna(); X.head(3).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b9d32-617a-412a-ad36-9510ba269403",
   "metadata": {},
   "source": [
    "- We extract the response ``log_volume`` and training indicator `train`.\n",
    "- We keep only the lagged versions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbd0921f-b72d-4669-bf31-8665ee8f88d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DJ_return_1', 'log_volume_1', 'log_volatility_1', 'DJ_return_2',\n",
       "       'log_volume_2', 'log_volatility_2', 'DJ_return_3', 'log_volume_3',\n",
       "       'log_volatility_3', 'DJ_return_4', 'log_volume_4', 'log_volatility_4',\n",
       "       'DJ_return_5', 'log_volume_5', 'log_volatility_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y, train = X['log_volume'], X['train']\n",
    "X = X.drop(columns=['train'] + cols)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58876f73-1b19-4dc8-aaae-8a09c0a919e0",
   "metadata": {},
   "source": [
    "- We fit a simple linear model and use `score()` to compute the $R^2$ on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446a7d5-55cb-45d5-917e-c1e8478d0925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41289129385625223"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = LinearRegression()\n",
    "# LinearRegression() add an intercept by default\n",
    "M.fit(X[train], Y[train])\n",
    "M.score(X[~train], Y[~train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9945c51-7e1b-49ec-8dec-2211ffa7f822",
   "metadata": {},
   "source": [
    "- We refit this model, including the factor variable `day_of_week`.\n",
    "- We use `get_dummies()` from `pandas` to form the indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6b5e024-f93a-418c-ac42-a3050b230c56",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "X_day = pd.concat( [ X, pd.get_dummies(NYSE['day_of_week']) ],\n",
    "                  axis=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712b606-dde3-4f1d-accd-bb48dbd20fb4",
   "metadata": {},
   "source": [
    "- We don't need to reinstantiate the linear regression model since its `fit()` method accepts both the design matrix and the response directly.\n",
    "- The model achieves an $R^2$ of 46%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae07530f-3736-407e-aed6-5b09466878e1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4595563133053274"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.fit(X_day[train], Y[train])\n",
    "M.score(X_day[~train], Y[~train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa05f6e",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e045e",
   "metadata": {},
   "source": [
    "- We must reshape the data to fit RNN. The `input_shape` argument to the layer `nn.RNN()` requires 5 lagged versions of each feature, it means that it requires 5 columns for each of 3 features.\n",
    "- The `nn.RNN()` layer expects the first row of each observation to be lag 5, then lag 4, and so on.\n",
    "- We rearrange the columns of the data frame so that the variables are correctly lagged. We use the `reindex()` method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b179cc16-8d3a-4f64-b535-74bd0a6f50fa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DJ_return_5</th>\n",
       "      <th>log_volume_5</th>\n",
       "      <th>log_volatility_5</th>\n",
       "      <th>DJ_return_4</th>\n",
       "      <th>log_volume_4</th>\n",
       "      <th>log_volatility_4</th>\n",
       "      <th>DJ_return_3</th>\n",
       "      <th>log_volume_3</th>\n",
       "      <th>log_volatility_3</th>\n",
       "      <th>DJ_return_2</th>\n",
       "      <th>log_volume_2</th>\n",
       "      <th>log_volatility_2</th>\n",
       "      <th>DJ_return_1</th>\n",
       "      <th>log_volume_1</th>\n",
       "      <th>log_volatility_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-12-10</th>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-4.36</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-11</th>\n",
       "      <td>0.91</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-12</th>\n",
       "      <td>0.43</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DJ_return_5  log_volume_5  log_volatility_5  DJ_return_4  \\\n",
       "date                                                                   \n",
       "1962-12-10        -0.55          0.18             -4.36         0.91   \n",
       "1962-12-11         0.91          1.52             -2.53         0.43   \n",
       "1962-12-12         0.43          2.28             -2.42        -0.43   \n",
       "\n",
       "            log_volume_4  log_volatility_4  DJ_return_3  log_volume_3  \\\n",
       "date                                                                    \n",
       "1962-12-10          1.52             -2.53         0.43          2.28   \n",
       "1962-12-11          2.28             -2.42        -0.43          0.94   \n",
       "1962-12-12          0.94             -2.37         0.05          0.22   \n",
       "\n",
       "            log_volatility_3  DJ_return_2  log_volume_2  log_volatility_2  \\\n",
       "date                                                                        \n",
       "1962-12-10             -2.42        -0.43          0.94             -2.37   \n",
       "1962-12-11             -2.37         0.05          0.22             -2.50   \n",
       "1962-12-12             -2.50        -1.30          0.61             -1.37   \n",
       "\n",
       "            DJ_return_1  log_volume_1  log_volatility_1  \n",
       "date                                                     \n",
       "1962-12-10         0.05          0.22             -2.50  \n",
       "1962-12-11        -1.30          0.61             -1.37  \n",
       "1962-12-12        -0.01         -0.01             -1.51  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_cols = []\n",
    "for lag in range(5,0,-1):\n",
    "    for col in cols:\n",
    "        ordered_cols.append('{0}_{1}'.format(col, lag))\n",
    "X = X.reindex(columns=ordered_cols)\n",
    "X.head(3).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83ba6b-7287-443b-993f-b6b1dc7f954f",
   "metadata": {},
   "source": [
    "- We now reshape the data.\n",
    "- ``to_numpy().reshape((-1,5,3)`` tells `NumPy` to reshape the data into a 3D array with second dimension of size 5 and third dimension of size 3. It will automatically determine the size of the first dimension. Simply, it will reshape the data into a n groups of a 5x3 matrix.\n",
    "- The result is 6046 groups of 5x3 matrices.\n",
    "- We show the first two groups.\n",
    "    - For each group, the first row is lag 5 ofr DJ_return, log_volume, and log_volatility.\n",
    "    - The second row is lag 4 of DJ_return, log_volume, and log_volatility. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cbd429d-3b27-4283-9ce8-10686c199910",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6046, 5, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.54982334,  0.17507497, -4.35707786],\n",
       "        [ 0.90519995,  1.51729071, -2.52905765],\n",
       "        [ 0.43481275,  2.28378937, -2.41803694],\n",
       "        [-0.43139673,  0.93517558, -2.36652094],\n",
       "        [ 0.04634026,  0.22477858, -2.5009701 ]],\n",
       "\n",
       "       [[ 0.90519995,  1.51729071, -2.52905765],\n",
       "        [ 0.43481275,  2.28378937, -2.41803694],\n",
       "        [-0.43139673,  0.93517558, -2.36652094],\n",
       "        [ 0.04634026,  0.22477858, -2.5009701 ],\n",
       "        [-1.30412619,  0.60591805, -1.366028  ]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rnn = X.to_numpy().reshape((-1,5,3))\n",
    "print(X_rnn.shape)\n",
    "X_rnn[:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f313d",
   "metadata": {},
   "source": [
    "- We define class ``NYSEModel`` that inherits from `nn.Module`.\n",
    "    - ``super(NYSEModel, self).__init__()`` calls the constructor of the parent class.\n",
    "    - ``self.rnn = nn.RNN(3, 12, batch_first=True)``  initializes a RNN layer:\n",
    "        - 3: The input size, i.e., the number of features at each time step.\n",
    "        - 12: The number of hidden units.\n",
    "        - `batch_first=True` specifies that the first dimension of the input is the batch size.\n",
    "    - ``self.dense = nn.Linear(12, 1)`` initializes a fully connected (dense) layer.\n",
    "        - 12: The input size, which matches the number of hidden units in the RNN.\n",
    "        - 1: The output size, which is a single value.\n",
    "    - ``self.dropout = nn.Dropout(0.1)`` initializes a dropout layer with a dropout rate of 10%.\n",
    "    - We define ``forward()`` method that specifies how the input is passed through the layers.\n",
    "        - ``val, h_n = self.rnn(x)``: This passes the input ``x`` through the RNN layer.\n",
    "            - ``val`` is the output at each time step.\n",
    "            - ``h_n`` is the hidden state at the final time step.\n",
    "        - ``val = self.dense(self.dropout(val[:,-1]))``: This passes the output through the dense layer with dropout.\n",
    "            - ``val[:,-1]`` extracts the output at the final time step.\n",
    "        - ``torch.flatten(val)`` flattens the output of the dense layer to a 1D tensor.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f7834f9-2b3c-4905-97ab-18928aaa131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYSEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NYSEModel, self).__init__()\n",
    "        self.rnn = nn.RNN(3,\n",
    "                          12,\n",
    "                          batch_first=True)\n",
    "        self.dense = nn.Linear(12, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        val, h_n = self.rnn(x)\n",
    "        val = self.dense(self.dropout(val[:,-1]))\n",
    "        return torch.flatten(val)\n",
    "nyse_model = NYSEModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da408b7d",
   "metadata": {},
   "source": [
    "- We form the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1624bace-6aae-4894-93e2-c12e235f127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for mask in [train, ~train]:\n",
    "    X_rnn_t = torch.tensor( np.asarray(X_rnn[mask].astype(np.float32)) )\n",
    "    Y_t = torch.tensor( np.asarray(Y[mask].astype(np.float32)) )\n",
    "    datasets.append( TensorDataset(X_rnn_t, Y_t) )\n",
    "nyse_train, nyse_test = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e6986-20e8-439b-bab5-f61c47f5866a",
   "metadata": {},
   "source": [
    "- We inspect the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7d1b2314-181d-4c17-b8e7-ff17f5cf4f29",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "NYSEModel                                [1770, 5, 3]              [1770]                    --\n",
       "├─RNN: 1-1                               [1770, 5, 3]              [1770, 5, 12]             204\n",
       "├─Dropout: 1-2                           [1770, 12]                [1770, 12]                --\n",
       "├─Linear: 1-3                            [1770, 12]                [1770, 1]                 13\n",
       "===================================================================================================================\n",
       "Total params: 217\n",
       "Trainable params: 217\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.83\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 0.86\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.97\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(nyse_model,\n",
    "        input_data=X_rnn_t,\n",
    "        col_names=['input_size',\n",
    "                   'output_size',\n",
    "                   'num_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc18089-d242-475e-a688-5ec30445cd6b",
   "metadata": {},
   "source": [
    "- We provide the `fit` function with test data for validation, allowing us to monitor and plot its progress on the test set. However, this should not influence early stopping to avoid biasing the test performance.\n",
    "- Both datasets are placed into a data module with a batch size of 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aae9d22f-4669-4e3f-9bdd-272d6265a950",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nyse_dm = SimpleDataModule(train_dataset=nyse_train,\n",
    "                           test_dataset=nyse_test,\n",
    "                           num_workers=min(4, 10),\n",
    "                           validation=nyse_test,\n",
    "                           batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740cf2e-5544-4236-97e0-d87337b374d9",
   "metadata": {},
   "source": [
    "- We run some data through our model to check the sizes match up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "199640d4-bace-45b6-b415-94fed4b5e05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([64]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(nyse_dm.train_dataloader()):\n",
    "    out = nyse_model(x)\n",
    "    print(y.size(), out.size())\n",
    "    if idx >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036525b-0580-41b0-9622-2947ac43873e",
   "metadata": {},
   "source": [
    "- We set up a trainer for a regression problem.\n",
    "- We request the $R^2$ metric to be computed at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8acdc679-b81f-438e-b6ae-1d00e71445c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_optimizer = RMSprop(nyse_model.parameters(), lr=0.001)\n",
    "nyse_module = SimpleModule.regression(nyse_model,\n",
    "                                      optimizer=nyse_optimizer,\n",
    "                                      metrics={'r2':R2Score()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae3ad1-53b3-481e-868c-e223c328832f",
   "metadata": {},
   "source": [
    "- The results on the test data are very similar to the linear AR model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f10fa016-2187-4b65-bb42-09c6aa3db163",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type      | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | model | NYSEModel | 217    | train\n",
      "1 | loss  | MSELoss   | 0      | train\n",
      "--------------------------------------------\n",
      "217       Trainable params\n",
      "0         Non-trainable params\n",
      "217       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6264728307723999     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.40544670820236206    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6264728307723999    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.40544670820236206   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6264728307723999, 'test_r2': 0.40544670820236206}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyse_trainer = Trainer(deterministic=True,\n",
    "                       max_epochs=200,\n",
    "                       enable_progress_bar=False,\n",
    "                       callbacks=[ErrorTracker()])\n",
    "nyse_trainer.fit(nyse_module,\n",
    "                 datamodule=nyse_dm)\n",
    "nyse_trainer.test(nyse_module,\n",
    "                  datamodule=nyse_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18092e5b",
   "metadata": {},
   "source": [
    "## Non-Linear AR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfbe6c4-ef1e-458c-82d3-92518ca2fa44",
   "metadata": {},
   "source": [
    "- We fit a model without the `nn.RNN()` layer by just using a `nn.Flatten()` layer instead. \n",
    "- This would be a nonlinear AR model.\n",
    "- If in addition we excluded the hidden layer, this would be equivalent to our earlier linear AR model.\n",
    "- We fit a nonlinear AR model using `X_day` that includes the `day_of_week` indicators.\n",
    "- We first create our test and training datasets and a corresponding data module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7618778-1640-489f-93a2-7127fbd398f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for mask in [train, ~train]:\n",
    "    X_day_t = torch.tensor(\n",
    "                   np.asarray(X_day[mask]).astype(np.float32))\n",
    "    Y_t = torch.tensor(np.asarray(Y[mask]).astype(np.float32))\n",
    "    datasets.append(TensorDataset(X_day_t, Y_t))\n",
    "day_train, day_test = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92698a2a-b054-4a31-b1fa-224a082bd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_dm = SimpleDataModule(train_dataset=day_train,\n",
    "                          test_dataset=day_test,\n",
    "                          num_workers=min(4, 10),\n",
    "                          validation=day_test,\n",
    "                          batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac6911",
   "metadata": {},
   "source": [
    "- We define class ``NonLinearARModel`` that inherits from `nn.Module`.\n",
    "    - ``super(NonLinearARModel, self).__init__()`` calls the constructor of the parent class.\n",
    "    - ``self._forward = nn.Sequential(...)`` initializes a sequential container that holds a sequence of layers.\n",
    "    - ``nn.Flatten()`` flattens the input.\n",
    "    - ``nn.Linear(20, 32)``: This is a fully connected (dense) layer with 20 input features and 32 output features.\n",
    "    - We define ``forward()`` method that specifies how the input is passed through the layers.\n",
    "        - ``self._forward(x)`` passes the input ``x`` through the layers in the sequential container.\n",
    "        - ``torch.flatten()`` flattens the output of the dense layer to a 1D tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba959f85-c77c-40b9-ba64-2480f337bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearARModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NonLinearARModel, self).__init__()\n",
    "        self._forward = nn.Sequential(nn.Flatten(),\n",
    "                                      nn.Linear(20, 32),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout(0.5),\n",
    "                                      nn.Linear(32, 1))\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(self._forward(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05800d79-bb32-4e4f-9322-9a19f94c8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_model = NonLinearARModel()\n",
    "nl_optimizer = RMSprop(nl_model.parameters(), lr=0.001)\n",
    "nl_module = SimpleModule.regression(nl_model,\n",
    "                                        optimizer=nl_optimizer,\n",
    "                                        metrics={'r2':R2Score()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bbc8d21a-b6e3-470e-87a1-08d566ebc93e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model | NonLinearARModel | 705    | train\n",
      "1 | loss  | MSELoss          | 0      | train\n",
      "---------------------------------------------------\n",
      "705       Trainable params\n",
      "0         Non-trainable params\n",
      "705       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.560681939125061     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.46788549423217773    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.560681939125061    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46788549423217773   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.560681939125061, 'test_r2': 0.46788549423217773}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_trainer = Trainer(deterministic=True,\n",
    "                     max_epochs=20,\n",
    "                     enable_progress_bar=False,\n",
    "                     callbacks=[ErrorTracker()])\n",
    "nl_trainer.fit(nl_module, datamodule=day_dm)\n",
    "nl_trainer.test(nl_module, datamodule=day_dm) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d480fe",
   "metadata": {},
   "source": [
    "- We see the test $R^2$ is a slight improvement over the linear AR model that also includes `day_of_week`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
